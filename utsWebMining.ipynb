{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"wblCcwrSkTrL463ew9HBaOydH\"\n",
    "consumer_secret = \"uCpAC4qsQ1gZTk9tk2nx2x0lkJTQYRIiwILZSzlWtxwxf186G5\"\n",
    "access_token = \"1150618299392069632-Yx0HDItOkuvbiHT4KBrSoKdSM3lh3D\"\n",
    "access_token_secret = \"iybEGs98DdvfsV5FTs0wzervU5pb9nI6Sh514gV9QI0Sm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "tweet = api.search(q='kebakaran -filter:retweets',lang=\"id\", count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=[]\n",
    "forcsv={}\n",
    "for hasil in tweet:\n",
    "    sorting=' '.join(re.sub(\"(@[A-Za-z-9]+)|(\\w+:\\/\\/\\S+)\",\" \",hasil.text).split())\n",
    "    text = re.sub('\\d+<[^>]*>', '', sorting)\n",
    "    emoticons = re.findall('(?::|;|=)()(?:-)?(?:\\)|\\(|D|P)',text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', ''))\n",
    "    array.append(text)\n",
    "    \n",
    " \n",
    "        \n",
    "forcsv['tweet']=array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet': ['gue udah ga mikir pas mati lampu kebakaran dimana udah capek banget tidur aja ampe pagi ',\n",
       "  'musibah itu kejadian yg diluar perbuatan orang tersebut tapi akibat alam misal bencana bisa longsor tenggelam k ',\n",
       "  '_dasco ituu korupsi loo pak bukan rumah kebakaran kalau korupsi itu yaa kejahatan bukan musibah ',\n",
       "  'ada apa dengan kebakaran hutan papua ',\n",
       "  '_ad panas nie yeee baru di dunia bong lo udh kepanasan kebakaran ']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(forcsv, columns= ['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gue', 'udah', 'ga', 'mikir', 'pas', 'mati', 'lampu', 'bakar', 'mana', 'udah', 'capek', 'banget', 'tidur', 'aja', 'ampe', 'pagi']\n",
      "['musibah', 'jadi', 'yg', 'luar', 'buat', 'orang', 'sebut', 'tapi', 'akibat', 'alam', 'misal', 'bencana', 'bisa', 'longsor', 'tenggelam', 'k']\n",
      "['musibah', 'jadi', 'luar', 'buat', 'orang', 'sebut', 'tapi', 'akibat', 'alam', 'misal', 'bencana', 'bisa', 'longsor', 'tenggelam', 'k']\n",
      "['musibah', 'jadi', 'luar', 'buat', 'orang', 'sebut', 'akibat', 'alam', 'misal', 'bencana', 'bisa', 'longsor', 'tenggelam', 'k']\n",
      "['musibah', 'jadi', 'luar', 'buat', 'orang', 'sebut', 'akibat', 'alam', 'misal', 'bencana', 'longsor', 'tenggelam', 'k']\n",
      "['musibah', 'jadi', 'luar', 'buat', 'orang', 'sebut', 'akibat', 'alam', 'misal', 'bencana', 'longsor', 'tenggelam', 'k']\n",
      "['dasco', 'ituu', 'korupsi', 'pak', 'bukan', 'rumah', 'bakar', 'kalau', 'korupsi', 'itu', 'yaa', 'jahat', 'bukan', 'musibah']\n",
      "['dasco', 'ituu', 'korupsi', 'pak', 'bukan', 'rumah', 'bakar', 'kalau', 'korupsi', 'yaa', 'jahat', 'bukan', 'musibah']\n",
      "['dasco', 'ituu', 'korupsi', 'pak', 'bukan', 'rumah', 'bakar', 'kalau', 'korupsi', 'yaa', 'jahat', 'bukan', 'musibah']\n",
      "['apa', 'dengan', 'bakar', 'hutan', 'papua']\n",
      "['apa', 'bakar', 'hutan', 'papua']\n",
      "['apa', 'bakar', 'hutan', 'papua']\n",
      "['ad', 'panas', 'nie', 'yeee', 'baru', 'dunia', 'bong', 'lo', 'udh', 'panas', 'bakar']\n",
      "['ad', 'panas', 'nie', 'yeee', 'baru', 'dunia', 'bong', 'udh', 'panas', 'bakar']\n",
      "['ad', 'panas', 'nie', 'yeee', 'baru', 'dunia', 'bong', 'udh', 'panas', 'bakar']\n"
     ]
    }
   ],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "stop_factory = StopWordRemoverFactory().get_stop_words() \n",
    "more_stopword = ['yg','dm','lo','yee','loo']\n",
    "data = stop_factory + more_stopword \n",
    "tampung=[]\n",
    "\n",
    "for sastra in range(5):\n",
    "    \n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    sentence = df.loc[sastra, 'tweet']\n",
    "    output   = stemmer.stem(sentence)\n",
    "    \n",
    "    tokens = output.split()\n",
    "    for kal in tokens:\n",
    "        for stopp in data:\n",
    "            if kal == stopp:\n",
    "                tokens=list(filter(lambda a: a != stopp, tokens))\n",
    "                print(tokens)\n",
    "    s = \" \"\n",
    "    kalistop = s.join(tokens)\n",
    "    print(tokens)\n",
    "    #urutan proses preprocess: 1 stopword 2. tokennize 3. stemming 4.normalisasi\n",
    "    \n",
    "    tampung.append(kalistop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gue udah ga mikir pas mati lampu bakar mana udah capek banget tidur aja ampe pagi',\n",
       " 'musibah jadi luar buat orang sebut akibat alam misal bencana longsor tenggelam k',\n",
       " 'dasco ituu korupsi pak bukan rumah bakar kalau korupsi yaa jahat bukan musibah',\n",
       " 'apa bakar hutan papua',\n",
       " 'ad panas nie yeee baru dunia bong udh panas bakar']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tampung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ardatacrawl =np.array(tampung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = count.fit_transform(ardatacrawl)\n",
    "\n",
    "a=count.get_feature_names()\n",
    "\n",
    "bag = count.fit_transform(ardatacrawl)\n",
    "a=count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ad',\n",
       " 'aja',\n",
       " 'akibat',\n",
       " 'alam',\n",
       " 'ampe',\n",
       " 'apa',\n",
       " 'bakar',\n",
       " 'banget',\n",
       " 'baru',\n",
       " 'bencana',\n",
       " 'bong',\n",
       " 'buat',\n",
       " 'bukan',\n",
       " 'capek',\n",
       " 'dasco',\n",
       " 'dunia',\n",
       " 'ga',\n",
       " 'gue',\n",
       " 'hutan',\n",
       " 'ituu',\n",
       " 'jadi',\n",
       " 'jahat',\n",
       " 'kalau',\n",
       " 'korupsi',\n",
       " 'lampu',\n",
       " 'longsor',\n",
       " 'luar',\n",
       " 'mana',\n",
       " 'mati',\n",
       " 'mikir',\n",
       " 'misal',\n",
       " 'musibah',\n",
       " 'nie',\n",
       " 'orang',\n",
       " 'pagi',\n",
       " 'pak',\n",
       " 'panas',\n",
       " 'papua',\n",
       " 'pas',\n",
       " 'rumah',\n",
       " 'sebut',\n",
       " 'tenggelam',\n",
       " 'tidur',\n",
       " 'udah',\n",
       " 'udh',\n",
       " 'yaa',\n",
       " 'yeee']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.2403027  0.         0.         0.2403027  0.\n",
      "  0.13538235 0.2403027  0.         0.         0.         0.\n",
      "  0.         0.2403027  0.         0.         0.2403027  0.2403027\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.2403027  0.         0.         0.2403027  0.2403027  0.2403027\n",
      "  0.         0.         0.         0.         0.2403027  0.\n",
      "  0.         0.         0.2403027  0.         0.         0.\n",
      "  0.2403027  0.48060541 0.         0.         0.        ]\n",
      " [0.         0.         0.29296785 0.29296785 0.         0.\n",
      "  0.         0.         0.         0.29296785 0.         0.29296785\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29296785 0.         0.         0.\n",
      "  0.         0.29296785 0.29296785 0.         0.         0.\n",
      "  0.29296785 0.23636462 0.         0.29296785 0.         0.\n",
      "  0.         0.         0.         0.         0.29296785 0.29296785\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.1409853  0.         0.         0.         0.         0.\n",
      "  0.5004958  0.         0.2502479  0.         0.         0.\n",
      "  0.         0.2502479  0.         0.2502479  0.2502479  0.5004958\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20189843 0.         0.         0.         0.2502479\n",
      "  0.         0.         0.         0.2502479  0.         0.\n",
      "  0.         0.         0.         0.2502479  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.54903633\n",
      "  0.30931749 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.54903633 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.54903633 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.29725329 0.         0.         0.         0.         0.\n",
      "  0.16746732 0.         0.29725329 0.         0.29725329 0.\n",
      "  0.         0.         0.         0.29725329 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29725329 0.         0.         0.\n",
      "  0.59450658 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29725329 0.         0.29725329]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf=True, \n",
    "                         norm='l2', \n",
    "                         smooth_idf=True)\n",
    "zxas =tfidf.fit_transform(count.fit_transform(ardatacrawl)).toarray()\n",
    "print(tfidf.fit_transform(count.fit_transform(ardatacrawl)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl=pd.DataFrame(zxas,columns=[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ad</th>\n",
       "      <th>aja</th>\n",
       "      <th>akibat</th>\n",
       "      <th>alam</th>\n",
       "      <th>ampe</th>\n",
       "      <th>apa</th>\n",
       "      <th>bakar</th>\n",
       "      <th>banget</th>\n",
       "      <th>baru</th>\n",
       "      <th>bencana</th>\n",
       "      <th>...</th>\n",
       "      <th>papua</th>\n",
       "      <th>pas</th>\n",
       "      <th>rumah</th>\n",
       "      <th>sebut</th>\n",
       "      <th>tenggelam</th>\n",
       "      <th>tidur</th>\n",
       "      <th>udah</th>\n",
       "      <th>udh</th>\n",
       "      <th>yaa</th>\n",
       "      <th>yeee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135382</td>\n",
       "      <td>0.240303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240303</td>\n",
       "      <td>0.480605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292968</td>\n",
       "      <td>0.292968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292968</td>\n",
       "      <td>0.292968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250248</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549036</td>\n",
       "      <td>0.309317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.297253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ad       aja    akibat      alam      ampe       apa     bakar  \\\n",
       "0  0.000000  0.240303  0.000000  0.000000  0.240303  0.000000  0.135382   \n",
       "1  0.000000  0.000000  0.292968  0.292968  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.140985   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.549036  0.309317   \n",
       "4  0.297253  0.000000  0.000000  0.000000  0.000000  0.000000  0.167467   \n",
       "\n",
       "     banget      baru   bencana  ...     papua       pas     rumah     sebut  \\\n",
       "0  0.240303  0.000000  0.000000  ...  0.000000  0.240303  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.292968  ...  0.000000  0.000000  0.000000  0.292968   \n",
       "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.250248  0.000000   \n",
       "3  0.000000  0.000000  0.000000  ...  0.549036  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.297253  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "  tenggelam     tidur      udah       udh       yaa      yeee  \n",
       "0  0.000000  0.240303  0.480605  0.000000  0.000000  0.000000  \n",
       "1  0.292968  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.250248  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  0.297253  0.000000  0.297253  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.to_csv (r'output.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "craw=pd.DataFrame(forcsv, columns= ['tweet'])\n",
    "craw.to_csv (r'crawling.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
